{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObIUkPvDlPsOBx0fn5rZCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ziyu0118/workspace/blob/main/Word2Vec2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install fontconfig -y # Install fontconfig\n",
        "!fc-cache -fv # Rebuild font cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQZVy-DFBL55",
        "outputId": "dc85f397-1630-4e22-cd0c-968b4b0eb7cb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fontconfig is already the newest version (2.13.1-4.2ubuntu5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csscxcGt7TYj",
        "outputId": "ceb35a6e-4d69-46ff-d08b-9e1b59dce926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib\n",
        "from pylab import *\n",
        "mpl.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "import numpy as np\n",
        "tf.compat.v1.reset_default_graph()\n",
        "print(\"step 1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [ \"i like dog\", \"i like cat\", \"i like animal\",\n",
        "              \"dog cat animal\", \"apple cat dog like\", \"dog fish milk like\",\n",
        "              \"dog cat eyes like\", \"i like apple\", \"apple i hate\",\n",
        "              \"apple i movie book music like\", \"cat dog hate\", \"cat dog like\"]\n",
        "print(\"step 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYoTeQqg8OD1",
        "outputId": "ba5583ed-6be8-4677-e69a-5661698679d7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_sequence = \" \".join(sentences).split()#得到所有词汇\n",
        "\n",
        "word_list = \" \".join(sentences).split()\n",
        "\n",
        "word_list = list(set(word_list))#词汇去重\n",
        "#字典\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "\n",
        "\n",
        "print(\"step 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL2D1Xc49B3e",
        "outputId": "89bea6a0-1709-4c93-9061-cf009dc84107"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20#随机选取的数量，为后面训练多轮，每轮选择的个数\n",
        "embedding_size = 2 # To show 2 dim embedding graph,词向量为2维\n",
        "voc_size = len(word_list)#13个单词，词汇量个数\n",
        "print(\"step 4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYzABcOQ92kc",
        "outputId": "970b1bd2-88db-4bf9-9e81-ea033270f3f2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams = []\n",
        "for i in range(1, len(word_sequence) - 1):#除掉第一个字和最后一个字\n",
        "    target = word_dict[word_sequence[i]]#得到目标字\n",
        "    context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]#上下文字，word_dict为字典{词：数字}\n",
        "\n",
        "    for w in context:\n",
        "        skip_grams.append([target, w])#得到[目标字，上一个字],[目标字，下一个字] 即类似[[1, 3], [1, 9],\n",
        "print(\"step 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k3_4vI395-p",
        "outputId": "27ef72d6-dacc-468b-8a80-58e3a26c98c7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot标签化\n",
        "def random_batch(data, size):\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    np.random.seed(1)\n",
        "    random_index = np.random.choice(range(len(data)), size, replace=False)#从生成的skip_grams词语对里，随机抽取size个\n",
        "\n",
        "    for i in random_index:\n",
        "        random_inputs.append(np.eye(voc_size)[data[i][0]])  # target\n",
        "        random_labels.append(np.eye(voc_size)[data[i][1]])  # context word\n",
        "\n",
        "    return random_inputs, random_labels\n",
        "print(\"step 6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm8yLFHp98nG",
        "outputId": "9717d136-caa1-4919-ebba-2c008f63509e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution() # This line disables eager execution.\n",
        "\n",
        "# Model\n",
        "inputs = tf.compat.v1.placeholder(tf.float32, shape=[None, voc_size])#one-hot数组\n",
        "labels = tf.compat.v1.placeholder(tf.float32, shape=[None, voc_size])#one-hot数组\n",
        "\n",
        "# W and WT is not Traspose relationship\n",
        "W = tf.Variable(tf.random.uniform([voc_size, embedding_size], -1.0, 1.0))\n",
        "WT = tf.Variable(tf.random.uniform([embedding_size, voc_size], -1.0, 1.0))\n",
        "\n",
        "hidden_layer = tf.matmul(inputs, W) # [batch_size, embedding_size]\n",
        "output_layer = tf.matmul(hidden_layer, WT) # [batch_size, voc_size]\n",
        "\n",
        "cost = tf.compat.v1.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=labels))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "print(\"step 7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zh3cnwg9_mw",
        "outputId": "d3ded50b-4d89-4174-b1d8-5424cfebace1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.compat.v1.Session() as sess:\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(5000):\n",
        "        batch_inputs, batch_labels = random_batch(skip_grams, batch_size)\n",
        "        _, loss = sess.run([optimizer, cost], feed_dict={inputs: batch_inputs, labels: batch_labels})\n",
        "\n",
        "        if (epoch + 1)%1000 == 0:\n",
        "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "        trained_embeddings = W.eval()\n",
        "\n",
        "print(\"step 8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxsahTGOAV7w",
        "outputId": "331c3478-2f6c-42dc-ceae-7d93fb0aebd2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000 cost = 1.409942\n",
            "Epoch: 2000 cost = 0.986923\n",
            "Epoch: 3000 cost = 0.902257\n",
            "Epoch: 4000 cost = 0.865784\n",
            "Epoch: 5000 cost = 0.844166\n",
            "step 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "font_names = [f.name for f in fm.fontManager.ttflist]\n",
        "\n",
        "print(font_names)\n",
        "\n",
        "for i, label in enumerate(word_list):\n",
        "    x, y = trained_embeddings[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
        "plt.title('Word Embedding')\n",
        "plt.savefig('word_embedding.png')\n",
        "plt.grid(True)\n",
        "#plt.show()\n",
        "plt.close()\n",
        "print(\"step 9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6UAnvgLA0Fv",
        "outputId": "f6e47c44-4470-436f-ecb8-cdde0cf54b4c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DejaVu Serif Display', 'DejaVu Serif', 'STIXSizeFiveSym', 'STIXNonUnicode', 'STIXSizeTwoSym', 'DejaVu Serif', 'STIXSizeOneSym', 'cmex10', 'STIXSizeFourSym', 'cmss10', 'STIXNonUnicode', 'DejaVu Sans', 'DejaVu Sans Display', 'DejaVu Sans Mono', 'cmtt10', 'STIXGeneral', 'DejaVu Sans', 'DejaVu Sans', 'DejaVu Serif', 'STIXSizeThreeSym', 'cmb10', 'STIXSizeFourSym', 'DejaVu Sans Mono', 'DejaVu Sans Mono', 'DejaVu Sans Mono', 'STIXNonUnicode', 'cmmi10', 'DejaVu Serif', 'STIXGeneral', 'STIXSizeThreeSym', 'STIXGeneral', 'cmsy10', 'DejaVu Sans', 'STIXGeneral', 'STIXNonUnicode', 'STIXSizeTwoSym', 'STIXSizeOneSym', 'cmr10', 'Liberation Mono', 'Liberation Sans Narrow', 'Liberation Sans', 'Liberation Sans Narrow', 'Liberation Sans', 'Liberation Serif', 'Liberation Mono', 'Liberation Serif', 'Liberation Mono', 'Humor Sans', 'Liberation Serif', 'Liberation Sans', 'Liberation Sans Narrow', 'Liberation Serif', 'Liberation Mono', 'Liberation Sans Narrow', 'Liberation Sans']\n",
            "step 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xod3bXfQBJeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}